{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01: Data Exploration\n",
    "\n",
    "**小红帽 (Little Red Riding Hood) — Initial Data Survey**\n",
    "\n",
    "This notebook provides an interactive overview of the extracted game data before running formal experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from parsers import EventDumpParser, NarrativeExtractionParser, load_json_data\n",
    "from visualization import setup_style, COLORS\n",
    "\n",
    "setup_style()\n",
    "print(\"Modules loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Event Dump Overview\n",
    "\n",
    "The `EventTextDump.txt` contains raw RPG Maker event commands exported from the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and parse the event dump\n",
    "parser = EventDumpParser('../data/EventTextDump.txt')\n",
    "parser.parse()\n",
    "\n",
    "print(f\"Total maps: {len(parser.maps)}\")\n",
    "print(f\"Total events: {sum(len(m['events']) for m in parser.maps.values())}\")\n",
    "print(f\"Total commands: {sum(sum(len(e['commands']) for e in m['events'].values()) for m in parser.maps.values())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview some raw data\n",
    "with open('../data/EventTextDump.txt', 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()[:50]\n",
    "    \n",
    "print(\"First 50 lines of EventTextDump.txt:\")\n",
    "print(\"=\" * 60)\n",
    "for line in lines:\n",
    "    print(line.rstrip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Command Type Distribution\n",
    "\n",
    "Let's see what types of commands are most common in the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count command types across all maps\n",
    "command_counts = {}\n",
    "for map_data in parser.maps.values():\n",
    "    for event_data in map_data['events'].values():\n",
    "        for cmd in event_data['commands']:\n",
    "            cmd_type = cmd.get('type', 'unknown')\n",
    "            command_counts[cmd_type] = command_counts.get(cmd_type, 0) + 1\n",
    "\n",
    "# Sort by frequency\n",
    "sorted_counts = sorted(command_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Top 20 Command Types:\")\n",
    "print(\"-\" * 40)\n",
    "for cmd_type, count in sorted_counts[:20]:\n",
    "    print(f\"{cmd_type:30} {count:>6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize command distribution\n",
    "top_cmds = sorted_counts[:15]\n",
    "labels = [c[0] for c in top_cmds]\n",
    "values = [c[1] for c in top_cmds]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.barh(range(len(labels)), values, color=COLORS['story'])\n",
    "ax.set_yticks(range(len(labels)))\n",
    "ax.set_yticklabels(labels)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('Count')\n",
    "ax.set_title('Top 15 Command Types in EventTextDump')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Narrative Extraction Overview\n",
    "\n",
    "The `narrative_extraction.md` contains the human-annotated narrative structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load narrative structure\n",
    "narrative_parser = NarrativeExtractionParser('../data/narrative_extraction.md')\n",
    "narrative_parser.parse()\n",
    "\n",
    "print(f\"Arcs: {len(narrative_parser.arcs)}\")\n",
    "print(f\"Total sequences: {sum(len(arc['sequences']) for arc in narrative_parser.arcs.values())}\")\n",
    "print(f\"Total beats: {sum(sum(len(seq['beats']) for seq in arc['sequences'].values()) for arc in narrative_parser.arcs.values())}\")\n",
    "print(f\"Characters: {len(narrative_parser.characters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the arcs\n",
    "print(\"Narrative Arcs:\")\n",
    "print(\"=\" * 60)\n",
    "for arc_id, arc_data in narrative_parser.arcs.items():\n",
    "    print(f\"\\nArc {arc_id}: {arc_data.get('title', 'Untitled')}\")\n",
    "    for seq_id, seq_data in arc_data['sequences'].items():\n",
    "        print(f\"  └─ Sequence {seq_id}: {seq_data.get('title', 'Untitled')} ({len(seq_data['beats'])} beats)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dialogue Extraction\n",
    "\n",
    "Let's extract and preview dialogue from the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all dialogues\n",
    "dialogues = parser.extract_dialogue()\n",
    "print(f\"Total dialogue segments: {len(dialogues)}\")\n",
    "\n",
    "# Preview first 10\n",
    "print(\"\\nSample dialogues:\")\n",
    "print(\"-\" * 60)\n",
    "for d in dialogues[:10]:\n",
    "    map_name = d.get('map_name', d.get('map_id', 'Unknown'))\n",
    "    text = d.get('text', '')[:50]\n",
    "    print(f\"[{map_name}] {text}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Context Keywords\n",
    "\n",
    "Review the keyword lists used for semantic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load context keywords\n",
    "keywords = load_json_data('../data/context_keywords.json')\n",
    "\n",
    "print(\"Entities:\")\n",
    "print(keywords.get('entities', []))\n",
    "\n",
    "print(\"\\nThemes:\")\n",
    "print(keywords.get('themes', []))\n",
    "\n",
    "print(\"\\nMotif Contexts:\")\n",
    "for context, terms in keywords.get('motif_contexts', {}).items():\n",
    "    print(f\"  {context}: {terms}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Quick Statistics\n",
    "\n",
    "Summary statistics for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate some basic statistics\n",
    "stats = {\n",
    "    'Event Dump': {\n",
    "        'Maps': len(parser.maps),\n",
    "        'Events': sum(len(m['events']) for m in parser.maps.values()),\n",
    "        'Commands': sum(sum(len(e['commands']) for e in m['events'].values()) for m in parser.maps.values()),\n",
    "        'Dialogues': len(dialogues)\n",
    "    },\n",
    "    'Narrative Structure': {\n",
    "        'Arcs': len(narrative_parser.arcs),\n",
    "        'Sequences': sum(len(arc['sequences']) for arc in narrative_parser.arcs.values()),\n",
    "        'Beats': sum(sum(len(seq['beats']) for seq in arc['sequences'].values()) for arc in narrative_parser.arcs.values()),\n",
    "        'Characters': len(narrative_parser.characters)\n",
    "    },\n",
    "    'Keywords': {\n",
    "        'Entities': len(keywords.get('entities', [])),\n",
    "        'Themes': len(keywords.get('themes', [])),\n",
    "        'Motif Contexts': len(keywords.get('motif_contexts', {}))\n",
    "    }\n",
    "}\n",
    "\n",
    "df_stats = pd.DataFrame(stats).T\n",
    "print(\"Dataset Summary:\")\n",
    "print(df_stats.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Next**: Proceed to `02_alignment_deep_dive.ipynb` to explore the structural alignment analysis in detail."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
